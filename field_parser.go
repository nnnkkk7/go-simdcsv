//go:build goexperiment.simd && amd64

//nolint:gosec // G115: Integer conversions are safe - values bounded by buffer size (max ~2GB)
package simdcsv

import (
	"math/bits"
	"strings"
)

// stage2State holds state carried between chunks
type stage2State struct {
	quoted                   bool   // Inside quote state
	fieldStart               uint64 // Current field start offset
	quoteAdjust              uint64 // Length adjustment for quotes
	lastSeparatorOrDelimiter int64  // Last separator position (-1 for initial)
	lastClosingQuote         int64  // Last closing quote position (-1 for invalid)
}

// stage2Result represents Stage 2 processing result
type stage2Result struct {
	fields []fieldInfo // All field information
	rows   []rowInfo   // All row information
}

// fieldInfo holds field position information
type fieldInfo struct {
	start         uint64 // Start offset in buffer
	length        uint64 // Field length (after quote removal)
	needsUnescape bool   // Needs double quote unescaping
}

// rowInfo holds row metadata
type rowInfo struct {
	firstField int // First field index in fields array
	fieldCount int // Number of fields in this row
	lineNum    int // Original input line number (for error reporting)
}

// newStage2Result initializes a Stage 2 result with pre-allocated slices
func newStage2Result(estimatedFields, estimatedRows int) *stage2Result {
	return &stage2Result{
		fields: make([]fieldInfo, 0, estimatedFields),
		rows:   make([]rowInfo, 0, estimatedRows),
	}
}

// stage2Process extracts fields and rows from Stage 1 result
// This is the main extraction function that processes masks generated by Stage 1
func stage2Process(buf []byte, s1result *stage1Result) *stage2Result {
	// Handle empty input
	if len(buf) == 0 || s1result.chunkCount == 0 {
		return &stage2Result{
			fields: []fieldInfo{},
			rows:   []rowInfo{},
		}
	}

	// Initialize result with estimated capacities
	// Assume average field length of 10 bytes and row length of 50 bytes
	estimatedFields := len(buf) / 10
	estimatedRows := len(buf) / 50
	result := newStage2Result(estimatedFields, estimatedRows)

	// Initialize state with lastSeparatorOrDelimiter = -1
	state := stage2State{
		lastSeparatorOrDelimiter: -1,
		lastClosingQuote:         -1,
	}
	currentRowFirstField := 0
	lineNum := 1

	// Loop through all chunks, calling processChunkMasks for each
	for chunkIdx := 0; chunkIdx < s1result.chunkCount; chunkIdx++ {
		offset := uint64(chunkIdx * 64)
		sepMask := s1result.separatorMasks[chunkIdx]
		nlMask := s1result.newlineMasks[chunkIdx]

		// Get quote mask, default to 0 if not present
		var quoteMask uint64
		if chunkIdx < len(s1result.quoteMasks) {
			quoteMask = s1result.quoteMasks[chunkIdx]
		}

		// Process this chunk's masks
		processChunkMasks(buf, offset, sepMask, nlMask, quoteMask,
			&state, result, &currentRowFirstField, &lineNum)
	}

	// Handle file without trailing newline
	// If fieldStart is still within buffer bounds, there's a final field to record
	if state.fieldStart < uint64(len(buf)) {
		finalizeLastField(buf, &state, result, currentRowFirstField, lineNum)
	}

	// Mark fields needing double quote unescaping based on postProcChunks
	if len(s1result.postProcChunks) > 0 {
		postProcessFields(buf, result, s1result.postProcChunks)
	}

	return result
}

// processChunkMasks processes one chunk's masks
// Uses bits.TrailingZeros64 to find bit positions and processes
// separator, newline, and quote events in order
func processChunkMasks(
	buf []byte, offset uint64,
	sepMask, nlMask, quoteMask uint64,
	state *stage2State, result *stage2Result,
	currentRowFirstField *int, lineNum *int,
) {
	for sepMask != 0 || nlMask != 0 || quoteMask != 0 {
		sepPos := trailingZerosOr64(sepMask)
		nlPos := trailingZerosOr64(nlMask)
		quotePos := trailingZerosOr64(quoteMask)

		minPos := minOfThree(quotePos, sepPos, nlPos)
		if minPos >= 64 {
			break
		}

		switch minPos {
		case quotePos:
			processQuoteEvent(offset+uint64(quotePos), state)
			quoteMask = clearBit(quoteMask, quotePos)

		case sepPos:
			if !state.quoted {
				recordField(offset+uint64(sepPos), state, result)
			}
			sepMask = clearBit(sepMask, sepPos)

		default: // nlPos
			if !state.quoted {
				recordField(offset+uint64(nlPos), state, result)
				recordRow(result, currentRowFirstField, lineNum)
			}
			nlMask = clearBit(nlMask, nlPos)
		}
	}
}

// trailingZerosOr64 returns bits.TrailingZeros64 or 64 if mask is 0.
func trailingZerosOr64(mask uint64) int {
	if mask == 0 {
		return 64
	}
	return bits.TrailingZeros64(mask)
}

// clearBit clears a bit and all lower bits in a mask.
func clearBit(mask uint64, pos int) uint64 {
	return mask & (^uint64(1) << pos)
}

// processQuoteEvent handles a quote character
func processQuoteEvent(absPos uint64, state *stage2State) {
	if !state.quoted {
		state.quoted = true
		state.quoteAdjust = 1
	} else {
		state.quoted = false
		state.quoteAdjust++
		state.lastClosingQuote = int64(absPos)
	}
}

// recordField calculates field bounds and appends to result
func recordField(absPos uint64, state *stage2State, result *stage2Result) {
	start := state.fieldStart + state.quoteAdjust
	fieldLen := calculateFieldLength(absPos, start, state)

	result.fields = append(result.fields, fieldInfo{
		start:  start,
		length: fieldLen,
	})

	state.fieldStart = absPos + 1
	state.quoteAdjust = 0
	state.lastSeparatorOrDelimiter = int64(absPos)
	state.lastClosingQuote = -1
}

// recordRow appends row info and updates row tracking state
func recordRow(result *stage2Result, currentRowFirstField, lineNum *int) {
	fieldCount := len(result.fields) - *currentRowFirstField
	result.rows = append(result.rows, rowInfo{
		firstField: *currentRowFirstField,
		fieldCount: fieldCount,
		lineNum:    *lineNum,
	})
	*currentRowFirstField = len(result.fields)
	(*lineNum)++
}

// calculateFieldLength computes field length, accounting for quoted fields
func calculateFieldLength(endPos, start uint64, state *stage2State) uint64 {
	if state.lastClosingQuote >= 0 && state.quoteAdjust > 0 {
		return uint64(state.lastClosingQuote) - start
	}
	if endPos > start {
		return endPos - start
	}
	return 0
}

// finalizeLastField handles the last field when file doesn't end with newline
func finalizeLastField(buf []byte, state *stage2State, result *stage2Result, currentRowFirstField, lineNum int) {
	start := state.fieldStart + state.quoteAdjust
	bufLen := uint64(len(buf))
	fieldLen := calculateFieldLength(bufLen, start, state)

	result.fields = append(result.fields, fieldInfo{
		start:  start,
		length: fieldLen,
	})

	fieldCount := len(result.fields) - currentRowFirstField
	result.rows = append(result.rows, rowInfo{
		firstField: currentRowFirstField,
		fieldCount: fieldCount,
		lineNum:    lineNum,
	})
}

// unescapeDoubleQuotes converts double quotes to single quotes
func unescapeDoubleQuotes(s string) string {
	// Fast path: no double quotes
	if !strings.Contains(s, `""`) {
		return s
	}
	return strings.ReplaceAll(s, `""`, `"`)
}

// postProcessFields marks fields needing double quote unescaping
// Fields that fall within chunks listed in postProcChunks are flagged
func postProcessFields(buf []byte, result *stage2Result, postProcChunks []int) {
	if len(postProcChunks) == 0 {
		return
	}

	// For each chunk that needs post-processing, find overlapping fields
	for _, chunkIdx := range postProcChunks {
		chunkStart := uint64(chunkIdx * 64)
		chunkEnd := chunkStart + 64

		// Search for fields that start within this chunk range
		for i := range result.fields {
			f := &result.fields[i]
			// Field overlaps with chunk if field starts within chunk
			// or field spans across chunk boundary
			fieldEnd := f.start + f.length
			if (f.start >= chunkStart && f.start < chunkEnd) ||
				(f.start < chunkStart && fieldEnd > chunkStart) {
				// Mark this field as needing unescape processing
				f.needsUnescape = true
			}
		}
	}
}

// extractFieldSafe safely extracts a field string from buffer
func extractFieldSafe(buf []byte, start, length uint64) string {
	if length == 0 {
		return ""
	}
	return string(buf[start : start+length])
}

// extractField extracts a field string, applying unescaping if needed
func extractField(buf []byte, field fieldInfo) string {
	s := extractFieldSafe(buf, field.start, field.length)
	if field.needsUnescape {
		s = unescapeDoubleQuotes(s)
	}
	return s
}
