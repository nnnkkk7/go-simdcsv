//go:build goexperiment.simd && amd64

//nolint:gosec // G115: Integer conversions are safe - values bounded by buffer size (max ~2GB)
package simdcsv

import (
	"math/bits"
	"strings"
)

// fieldNormalizer is a pre-compiled replacer for common field transformations.
// Using a single Replacer for both operations is more efficient than separate calls.
var fieldNormalizer = strings.NewReplacer(
	`""`, `"`, // Unescape double quotes
	"\r\n", "\n", // Normalize CRLF to LF
)

// parserState holds state carried between chunks during field parsing
type parserState struct {
	quoted                   bool   // Inside quote state
	fieldStart               uint64 // Current field start offset
	quoteAdjust              uint64 // Length adjustment for quotes
	lastSeparatorOrDelimiter int64  // Last separator position (-1 for initial)
	lastClosingQuote         int64  // Last closing quote position (-1 for invalid)
}

// parseResult represents the result of field parsing (extracted fields and rows)
type parseResult struct {
	fields []fieldInfo // All field information
	rows   []rowInfo   // All row information
}

// fieldInfo holds field position information
type fieldInfo struct {
	start         uint64 // Start offset in buffer (content start, after opening quote if quoted)
	length        uint64 // Field length (content length, excluding quotes)
	rawStart      uint64 // Raw start offset in buffer (including opening quote if quoted)
	rawEnd        uint64 // Raw end offset in buffer (position after field, at separator/newline)
	needsUnescape bool   // Needs double quote unescaping
}

// rowInfo holds row metadata
type rowInfo struct {
	firstField int // First field index in fields array
	fieldCount int // Number of fields in this row
	lineNum    int // Original input line number (for error reporting)
}

// parseBuffer extracts fields and rows from scan result
// This is the main extraction function that processes masks generated by scanBuffer
func parseBuffer(buf []byte, sr *scanResult) *parseResult {
	// Handle empty input
	if len(buf) == 0 || sr.chunkCount == 0 {
		return &parseResult{
			fields: []fieldInfo{},
			rows:   []rowInfo{},
		}
	}

	// Initialize result with estimated capacities
	estimatedFields := len(buf) / avgFieldLenEstimate
	estimatedRows := len(buf) / avgRowLenEstimate
	result := &parseResult{
		fields: make([]fieldInfo, 0, estimatedFields),
		rows:   make([]rowInfo, 0, estimatedRows),
	}

	// Initialize state with lastSeparatorOrDelimiter = -1
	state := parserState{
		lastSeparatorOrDelimiter: -1,
		lastClosingQuote:         -1,
	}
	currentRowFirstField := 0
	lineNum := 1

	// Loop through all chunks, calling processChunkMasks for each
	for chunkIdx := 0; chunkIdx < sr.chunkCount; chunkIdx++ {
		offset := uint64(chunkIdx * simdChunkSize)
		sepMask := sr.separatorMasks[chunkIdx]
		nlMask := sr.newlineMasks[chunkIdx]

		// Get quote mask, default to 0 if not present
		var quoteMask uint64
		if chunkIdx < len(sr.quoteMasks) {
			quoteMask = sr.quoteMasks[chunkIdx]
		}

		// Process this chunk's masks
		processChunkMasks(buf, offset, sepMask, nlMask, quoteMask,
			&state, result, &currentRowFirstField, &lineNum)
	}

	// Handle file without trailing newline
	// Need to finalize if:
	// 1. fieldStart < len(buf) - there's content for a final field
	// 2. fieldStart == len(buf) AND last char is not newline - empty final field after separator
	bufLen := uint64(len(buf))
	lastCharIsNewline := bufLen > 0 && (buf[bufLen-1] == '\n' || buf[bufLen-1] == '\r')
	needsFinalize := state.fieldStart < bufLen ||
		(state.fieldStart == bufLen && !lastCharIsNewline)
	if needsFinalize {
		finalizeLastField(buf, &state, result, currentRowFirstField, lineNum)
	}

	// Mark fields needing double quote unescaping based on postProcChunks
	if len(sr.postProcChunks) > 0 {
		postProcessFields(buf, result, sr.postProcChunks)
	}

	return result
}

// processChunkMasks processes one chunk's masks
// Uses bits.TrailingZeros64 to find bit positions and processes
// separator, newline, and quote events in order
func processChunkMasks(
	buf []byte, offset uint64,
	sepMask, nlMask, quoteMask uint64,
	state *parserState, result *parseResult,
	currentRowFirstField, lineNum *int,
) {
	for sepMask != 0 || nlMask != 0 || quoteMask != 0 {
		sepPos := trailingZerosOr64(sepMask)
		nlPos := trailingZerosOr64(nlMask)
		quotePos := trailingZerosOr64(quoteMask)

		minPos := minOfThree(quotePos, sepPos, nlPos)
		if minPos >= 64 {
			break
		}

		switch minPos {
		case quotePos:
			processQuoteEvent(offset+uint64(quotePos), state)
			quoteMask = clearBit(quoteMask, quotePos)

		case sepPos:
			if !state.quoted {
				recordField(buf, offset+uint64(sepPos), state, result, false)
			}
			sepMask = clearBit(sepMask, sepPos)

		default: // nlPos
			if !state.quoted {
				absPos := offset + uint64(nlPos)
				// Check if this is a blank line (no fields recorded yet, empty field)
				isBlankLine := *currentRowFirstField == len(result.fields) && state.fieldStart == absPos
				if isBlankLine {
					// Skip blank line - just advance past the newline
					state.fieldStart = absPos + 1
					state.quoteAdjust = 0
					state.lastClosingQuote = -1
					(*lineNum)++ // Still count the line number
				} else {
					recordField(buf, absPos, state, result, true)
					recordRow(result, currentRowFirstField, lineNum)
				}
			}
			nlMask = clearBit(nlMask, nlPos)
		}
	}
}

// trailingZerosOr64 returns bits.TrailingZeros64 or 64 if mask is 0.
func trailingZerosOr64(mask uint64) int {
	if mask == 0 {
		return 64
	}
	return bits.TrailingZeros64(mask)
}

// clearBit clears the bit at position pos in mask.
func clearBit(mask uint64, pos int) uint64 {
	return mask & ^(uint64(1) << pos)
}

// processQuoteEvent handles a quote character.
func processQuoteEvent(absPos uint64, state *parserState) {
	if !state.quoted {
		// Opening quote: mark that we're inside a quoted field
		// quoteAdjust = 1 means skip 1 byte (the opening quote) when extracting field content
		state.quoted = true
		state.quoteAdjust = 1
	} else {
		// Closing quote: mark end of quoted field
		// Don't increment quoteAdjust - it should remain 1 to only skip the opening quote
		state.quoted = false
		state.lastClosingQuote = int64(absPos)
	}
}

// recordField calculates field bounds and appends to result.
// If isNewline is true, it checks for and excludes a trailing CR (for CRLF handling).
func recordField(buf []byte, absPos uint64, state *parserState, result *parseResult, isNewline bool) {
	rawStart := state.fieldStart
	start := state.fieldStart + state.quoteAdjust
	endPos := absPos

	// For newline delimiters, check if the previous byte is CR (CRLF sequence)
	// and exclude it from the field content
	if isNewline && endPos > start && endPos > 0 && buf[endPos-1] == '\r' {
		endPos--
	}

	fieldLen := calculateFieldLength(endPos, start, state)

	result.fields = append(result.fields, fieldInfo{
		start:    start,
		length:   fieldLen,
		rawStart: rawStart,
		rawEnd:   absPos,
	})

	state.fieldStart = absPos + 1
	state.quoteAdjust = 0
	state.lastSeparatorOrDelimiter = int64(absPos)
	state.lastClosingQuote = -1
}

// recordRow appends row info and updates row tracking state
func recordRow(result *parseResult, currentRowFirstField, lineNum *int) {
	fieldCount := len(result.fields) - *currentRowFirstField
	result.rows = append(result.rows, rowInfo{
		firstField: *currentRowFirstField,
		fieldCount: fieldCount,
		lineNum:    *lineNum,
	})
	*currentRowFirstField = len(result.fields)
	(*lineNum)++
}

// calculateFieldLength computes field length, accounting for quoted fields.
// Returns 0 if calculation would result in underflow (invalid state).
func calculateFieldLength(endPos, start uint64, state *parserState) uint64 {
	if state.lastClosingQuote >= 0 && state.quoteAdjust > 0 {
		closeQuote := uint64(state.lastClosingQuote)
		if closeQuote > start {
			return closeQuote - start
		}
		return 0
	}
	if endPos > start {
		return endPos - start
	}
	return 0
}

// finalizeLastField handles the last field when file doesn't end with newline
func finalizeLastField(buf []byte, state *parserState, result *parseResult, currentRowFirstField, lineNum int) {
	rawStart := state.fieldStart
	start := state.fieldStart + state.quoteAdjust
	bufLen := uint64(len(buf))
	fieldLen := calculateFieldLength(bufLen, start, state)

	result.fields = append(result.fields, fieldInfo{
		start:    start,
		length:   fieldLen,
		rawStart: rawStart,
		rawEnd:   bufLen,
	})

	fieldCount := len(result.fields) - currentRowFirstField
	result.rows = append(result.rows, rowInfo{
		firstField: currentRowFirstField,
		fieldCount: fieldCount,
		lineNum:    lineNum,
	})
}

// postProcessFields marks fields needing double quote unescaping.
// Fields that overlap with chunks listed in postProcChunks are flagged.
func postProcessFields(buf []byte, result *parseResult, postProcChunks []int) {
	if len(postProcChunks) == 0 {
		return
	}

	chunkSet := make(map[int]struct{}, len(postProcChunks))
	for _, idx := range postProcChunks {
		chunkSet[idx] = struct{}{}
	}

	for i := range result.fields {
		f := &result.fields[i]

		startChunk := int(f.start / simdChunkSize)
		if _, ok := chunkSet[startChunk]; ok {
			f.needsUnescape = true
			continue
		}

		if f.length > 0 {
			endChunk := int((f.start + f.length - 1) / simdChunkSize)
			if endChunk != startChunk {
				for c := startChunk; c <= endChunk; c++ {
					if _, ok := chunkSet[c]; ok {
						f.needsUnescape = true
						break
					}
				}
			}
		}
	}
}

// extractFieldSafe safely extracts a field string from buffer.
// Returns empty string if bounds are invalid, ensuring no panic occurs.
func extractFieldSafe(buf []byte, start, length uint64) string {
	if length == 0 {
		return ""
	}
	bufLen := uint64(len(buf))
	if start >= bufLen {
		return ""
	}
	end := start + length
	if end > bufLen {
		end = bufLen
	}
	return string(buf[start:end])
}

// extractField extracts a field string, applying unescaping and CRLF normalization if needed.
func extractField(buf []byte, field fieldInfo) string {
	s := extractFieldSafe(buf, field.start, field.length)
	if len(s) == 0 {
		return s
	}

	// Fast path: check if any transformation is needed
	needsTransform := field.needsUnescape || containsCRLF(s)
	if !needsTransform {
		return s
	}

	// Apply transformations using pre-compiled replacer
	// This is more efficient than separate Contains + ReplaceAll calls
	return fieldNormalizer.Replace(s)
}

// containsCRLF checks if the string contains CRLF sequences.
// This is a fast check to avoid unnecessary replacer calls.
func containsCRLF(s string) bool {
	for i := 0; i < len(s)-1; i++ {
		if s[i] == '\r' && s[i+1] == '\n' {
			return true
		}
	}
	return false
}
