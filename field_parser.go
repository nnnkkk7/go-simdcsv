//go:build goexperiment.simd && amd64

//nolint:gosec // G115: Integer conversions are safe - values bounded by buffer size (max ~2GB)
package simdcsv

import (
	"math/bits"
	"simd/archsimd"
	"strings"
	"unsafe"
)

// parserState holds state carried between chunks during field parsing
type parserState struct {
	quoted                   bool   // Inside quote state
	fieldStart               uint64 // Current field start offset
	quoteAdjust              uint64 // Length adjustment for quotes
	lastSeparatorOrDelimiter int64  // Last separator position (-1 for initial)
	lastClosingQuote         int64  // Last closing quote position (-1 for invalid)
}

// parseResult represents the result of field parsing (extracted fields and rows)
type parseResult struct {
	fields []fieldInfo // All field information
	rows   []rowInfo   // All row information
}

// fieldInfo holds field position information
type fieldInfo struct {
	start         uint64 // Start offset in buffer
	length        uint64 // Field length (after quote removal)
	needsUnescape bool   // Needs double quote unescaping
}

// rowInfo holds row metadata
type rowInfo struct {
	firstField int // First field index in fields array
	fieldCount int // Number of fields in this row
	lineNum    int // Original input line number (for error reporting)
}

// newParseResult initializes a parse result with pre-allocated slices
func newParseResult(estimatedFields, estimatedRows int) *parseResult {
	return &parseResult{
		fields: make([]fieldInfo, 0, estimatedFields),
		rows:   make([]rowInfo, 0, estimatedRows),
	}
}

// parseBuffer extracts fields and rows from scan result
// This is the main extraction function that processes masks generated by scanBuffer
func parseBuffer(buf []byte, sr *scanResult) *parseResult {
	// Handle empty input
	if len(buf) == 0 || sr.chunkCount == 0 {
		return &parseResult{
			fields: []fieldInfo{},
			rows:   []rowInfo{},
		}
	}

	// Initialize result with estimated capacities
	estimatedFields := len(buf) / avgFieldLenEstimate
	estimatedRows := len(buf) / avgRowLenEstimate
	result := newParseResult(estimatedFields, estimatedRows)

	// Initialize state with lastSeparatorOrDelimiter = -1
	state := parserState{
		lastSeparatorOrDelimiter: -1,
		lastClosingQuote:         -1,
	}
	currentRowFirstField := 0
	lineNum := 1

	// Loop through all chunks, calling processChunkMasks for each
	for chunkIdx := 0; chunkIdx < sr.chunkCount; chunkIdx++ {
		offset := uint64(chunkIdx * simdChunkSize)
		sepMask := sr.separatorMasks[chunkIdx]
		nlMask := sr.newlineMasks[chunkIdx]

		// Get quote mask, default to 0 if not present
		var quoteMask uint64
		if chunkIdx < len(sr.quoteMasks) {
			quoteMask = sr.quoteMasks[chunkIdx]
		}

		// Process this chunk's masks
		processChunkMasks(buf, offset, sepMask, nlMask, quoteMask,
			&state, result, &currentRowFirstField, &lineNum)
	}

	// Handle file without trailing newline
	// Need to finalize if:
	// 1. fieldStart < len(buf) - there's content for a final field
	// 2. fieldStart == len(buf) AND last char is not newline - empty final field after separator
	bufLen := uint64(len(buf))
	lastCharIsNewline := bufLen > 0 && (buf[bufLen-1] == '\n' || buf[bufLen-1] == '\r')
	needsFinalize := state.fieldStart < bufLen ||
		(state.fieldStart == bufLen && !lastCharIsNewline)
	if needsFinalize {
		finalizeLastField(buf, &state, result, currentRowFirstField, lineNum)
	}

	// Mark fields needing double quote unescaping based on postProcChunks
	if len(sr.postProcChunks) > 0 {
		postProcessFields(buf, result, sr.postProcChunks)
	}

	return result
}

// processChunkMasks processes one chunk's masks
// Uses bits.TrailingZeros64 to find bit positions and processes
// separator, newline, and quote events in order
func processChunkMasks(
	buf []byte, offset uint64,
	sepMask, nlMask, quoteMask uint64,
	state *parserState, result *parseResult,
	currentRowFirstField, lineNum *int,
) {
	for sepMask != 0 || nlMask != 0 || quoteMask != 0 {
		sepPos := trailingZerosOr64(sepMask)
		nlPos := trailingZerosOr64(nlMask)
		quotePos := trailingZerosOr64(quoteMask)

		minPos := minOfThree(quotePos, sepPos, nlPos)
		if minPos >= 64 {
			break
		}

		switch minPos {
		case quotePos:
			processQuoteEvent(offset+uint64(quotePos), state)
			quoteMask = clearBit(quoteMask, quotePos)

		case sepPos:
			if !state.quoted {
				recordField(buf, offset+uint64(sepPos), state, result, false)
			}
			sepMask = clearBit(sepMask, sepPos)

		default: // nlPos
			if !state.quoted {
				absPos := offset + uint64(nlPos)
				// Check if this is a blank line (no fields recorded yet, empty field)
				isBlankLine := *currentRowFirstField == len(result.fields) && state.fieldStart == absPos
				if isBlankLine {
					// Skip blank line - just advance past the newline
					state.fieldStart = absPos + 1
					state.quoteAdjust = 0
					state.lastClosingQuote = -1
					(*lineNum)++ // Still count the line number
				} else {
					recordField(buf, absPos, state, result, true)
					recordRow(result, currentRowFirstField, lineNum)
				}
			}
			nlMask = clearBit(nlMask, nlPos)
		}
	}
}

// trailingZerosOr64 returns bits.TrailingZeros64 or 64 if mask is 0.
func trailingZerosOr64(mask uint64) int {
	if mask == 0 {
		return 64
	}
	return bits.TrailingZeros64(mask)
}

// clearBit clears the bit at position pos in mask.
func clearBit(mask uint64, pos int) uint64 {
	return mask & ^(uint64(1) << pos)
}

// processQuoteEvent handles a quote character.
func processQuoteEvent(absPos uint64, state *parserState) {
	if !state.quoted {
		// Opening quote: mark that we're inside a quoted field
		// quoteAdjust = 1 means skip 1 byte (the opening quote) when extracting field content
		state.quoted = true
		state.quoteAdjust = 1
	} else {
		// Closing quote: mark end of quoted field
		// Don't increment quoteAdjust - it should remain 1 to only skip the opening quote
		state.quoted = false
		state.lastClosingQuote = int64(absPos)
	}
}

// recordField calculates field bounds and appends to result.
// If isNewline is true, it checks for and excludes a trailing CR (for CRLF handling).
func recordField(buf []byte, absPos uint64, state *parserState, result *parseResult, isNewline bool) {
	start := state.fieldStart + state.quoteAdjust
	endPos := absPos

	// For newline delimiters, check if the previous byte is CR (CRLF sequence)
	// and exclude it from the field content
	if isNewline && endPos > start && endPos > 0 && buf[endPos-1] == '\r' {
		endPos--
	}

	fieldLen := calculateFieldLength(endPos, start, state)

	result.fields = append(result.fields, fieldInfo{
		start:  start,
		length: fieldLen,
	})

	state.fieldStart = absPos + 1
	state.quoteAdjust = 0
	state.lastSeparatorOrDelimiter = int64(absPos)
	state.lastClosingQuote = -1
}

// recordRow appends row info and updates row tracking state
func recordRow(result *parseResult, currentRowFirstField, lineNum *int) {
	fieldCount := len(result.fields) - *currentRowFirstField
	result.rows = append(result.rows, rowInfo{
		firstField: *currentRowFirstField,
		fieldCount: fieldCount,
		lineNum:    *lineNum,
	})
	*currentRowFirstField = len(result.fields)
	(*lineNum)++
}

// calculateFieldLength computes field length, accounting for quoted fields
func calculateFieldLength(endPos, start uint64, state *parserState) uint64 {
	if state.lastClosingQuote >= 0 && state.quoteAdjust > 0 {
		return uint64(state.lastClosingQuote) - start
	}
	if endPos > start {
		return endPos - start
	}
	return 0
}

// finalizeLastField handles the last field when file doesn't end with newline
func finalizeLastField(buf []byte, state *parserState, result *parseResult, currentRowFirstField, lineNum int) {
	start := state.fieldStart + state.quoteAdjust
	bufLen := uint64(len(buf))
	fieldLen := calculateFieldLength(bufLen, start, state)

	result.fields = append(result.fields, fieldInfo{
		start:  start,
		length: fieldLen,
	})

	fieldCount := len(result.fields) - currentRowFirstField
	result.rows = append(result.rows, rowInfo{
		firstField: currentRowFirstField,
		fieldCount: fieldCount,
		lineNum:    lineNum,
	})
}

// unescapeDoubleQuotes converts double quotes ("") to single quotes (").
// Dispatches to SIMD or scalar implementation based on CPU support and string size.
func unescapeDoubleQuotes(s string) string {
	// Use SIMD for strings >= simdMinThreshold bytes
	if useAVX512 && len(s) >= simdMinThreshold {
		return unescapeDoubleQuotesSIMD(s)
	}
	return unescapeDoubleQuotesScalar(s)
}

// unescapeDoubleQuotesScalar is the scalar implementation.
func unescapeDoubleQuotesScalar(s string) string {
	// Fast path: no double quotes
	if !strings.Contains(s, `""`) {
		return s
	}
	return strings.ReplaceAll(s, `""`, `"`)
}

// unescapeDoubleQuotesSIMD uses SIMD to find double quotes and unescape them.
func unescapeDoubleQuotesSIMD(s string) string {
	data := unsafe.Slice(unsafe.StringData(s), len(s))
	quoteCmp := archsimd.BroadcastInt8x32('"')

	// First pass: check if there are any double quotes using SIMD
	hasDoubleQuote := false
	i := 0
	for i+32 <= len(data) {
		chunk := archsimd.LoadInt8x32((*[32]int8)(unsafe.Pointer(&data[i])))
		mask := chunk.Equal(quoteCmp).ToBits()

		if mask != 0 {
			// Check if any quotes are followed by another quote
			for mask != 0 {
				pos := bits.TrailingZeros32(mask)
				absPos := i + pos
				if absPos+1 < len(data) && data[absPos+1] == '"' {
					hasDoubleQuote = true
					break
				}
				mask &= ^(uint32(1) << pos)
			}
			if hasDoubleQuote {
				break
			}
		}
		i += 32
	}

	// Check remaining bytes if no double quote found yet
	if !hasDoubleQuote {
		for ; i < len(data)-1; i++ {
			if data[i] == '"' && data[i+1] == '"' {
				hasDoubleQuote = true
				break
			}
		}
	}

	// Fast path: no double quotes found
	if !hasDoubleQuote {
		return s
	}

	// Second pass: build result with double quotes removed
	// Pre-allocate with estimated size (original - number of removed quotes)
	result := make([]byte, 0, len(s))
	lastWritten := 0

	i = 0
	for i+32 <= len(data) {
		chunk := archsimd.LoadInt8x32((*[32]int8)(unsafe.Pointer(&data[i])))
		mask := chunk.Equal(quoteCmp).ToBits()

		if mask != 0 {
			for mask != 0 {
				pos := bits.TrailingZeros32(mask)
				absPos := i + pos

				if absPos+1 < len(data) && data[absPos+1] == '"' {
					// Found double quote - write up to and including first quote
					result = append(result, s[lastWritten:absPos+1]...)
					lastWritten = absPos + 2 // Skip the second quote
					// Clear both bits if second quote is in same chunk
					mask &= ^(uint32(1) << pos)
					if pos+1 < 32 {
						mask &= ^(uint32(1) << (pos + 1))
					}
					continue
				}
				mask &= ^(uint32(1) << pos)
			}
		}
		i += 32
	}

	// Process remaining bytes
	for i < len(data)-1 {
		if data[i] == '"' && data[i+1] == '"' {
			result = append(result, s[lastWritten:i+1]...)
			lastWritten = i + 2
			i += 2
			continue
		}
		i++
	}

	// Append remaining content
	if lastWritten < len(s) {
		result = append(result, s[lastWritten:]...)
	}

	return string(result)
}

// postProcessFields marks fields needing double quote unescaping
// Fields that fall within chunks listed in postProcChunks are flagged
func postProcessFields(buf []byte, result *parseResult, postProcChunks []int) {
	if len(postProcChunks) == 0 {
		return
	}

	// For each chunk that needs post-processing, find overlapping fields
	for _, chunkIdx := range postProcChunks {
		chunkStart := uint64(chunkIdx * simdChunkSize)
		chunkEnd := chunkStart + 64

		// Search for fields that start within this chunk range
		for i := range result.fields {
			f := &result.fields[i]
			// Field overlaps with chunk if field starts within chunk
			// or field spans across chunk boundary
			fieldEnd := f.start + f.length
			if (f.start >= chunkStart && f.start < chunkEnd) ||
				(f.start < chunkStart && fieldEnd > chunkStart) {
				// Mark this field as needing unescape processing
				f.needsUnescape = true
			}
		}
	}
}

// extractFieldSafe safely extracts a field string from buffer
func extractFieldSafe(buf []byte, start, length uint64) string {
	if length == 0 {
		return ""
	}
	return string(buf[start : start+length])
}

// extractField extracts a field string, applying unescaping and CRLF normalization if needed.
func extractField(buf []byte, field fieldInfo) string {
	s := extractFieldSafe(buf, field.start, field.length)
	if field.needsUnescape {
		s = unescapeDoubleQuotes(s)
	}
	// Normalize CRLF to LF (matching encoding/csv behavior)
	if strings.Contains(s, "\r\n") {
		s = strings.ReplaceAll(s, "\r\n", "\n")
	}
	return s
}
