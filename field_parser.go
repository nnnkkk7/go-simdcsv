//go:build goexperiment.simd && amd64

//nolint:gosec // G115: Integer conversions are safe - values bounded by buffer size (max ~2GB)
package simdcsv

import (
	"math/bits"
	"strings"
)

// parserState holds state carried between chunks during field parsing
type parserState struct {
	quoted                   bool   // Inside quote state
	fieldStart               uint64 // Current field start offset
	quoteAdjust              uint64 // Length adjustment for quotes
	lastSeparatorOrDelimiter int64  // Last separator position (-1 for initial)
	lastClosingQuote         int64  // Last closing quote position (-1 for invalid)
}

// parseResult represents the result of field parsing (extracted fields and rows)
type parseResult struct {
	fields []fieldInfo // All field information
	rows   []rowInfo   // All row information
}

// fieldInfo holds field position information
type fieldInfo struct {
	start         uint64 // Start offset in buffer
	length        uint64 // Field length (after quote removal)
	needsUnescape bool   // Needs double quote unescaping
}

// rowInfo holds row metadata
type rowInfo struct {
	firstField int // First field index in fields array
	fieldCount int // Number of fields in this row
	lineNum    int // Original input line number (for error reporting)
}

// newParseResult initializes a parse result with pre-allocated slices
func newParseResult(estimatedFields, estimatedRows int) *parseResult {
	return &parseResult{
		fields: make([]fieldInfo, 0, estimatedFields),
		rows:   make([]rowInfo, 0, estimatedRows),
	}
}

// parseBuffer extracts fields and rows from scan result
// This is the main extraction function that processes masks generated by scanBuffer
func parseBuffer(buf []byte, sr *scanResult) *parseResult {
	// Handle empty input
	if len(buf) == 0 || sr.chunkCount == 0 {
		return &parseResult{
			fields: []fieldInfo{},
			rows:   []rowInfo{},
		}
	}

	// Initialize result with estimated capacities
	// Assume average field length of 10 bytes and row length of 50 bytes
	estimatedFields := len(buf) / 10
	estimatedRows := len(buf) / 50
	result := newParseResult(estimatedFields, estimatedRows)

	// Initialize state with lastSeparatorOrDelimiter = -1
	state := parserState{
		lastSeparatorOrDelimiter: -1,
		lastClosingQuote:         -1,
	}
	currentRowFirstField := 0
	lineNum := 1

	// Loop through all chunks, calling processChunkMasks for each
	for chunkIdx := 0; chunkIdx < sr.chunkCount; chunkIdx++ {
		offset := uint64(chunkIdx * 64)
		sepMask := sr.separatorMasks[chunkIdx]
		nlMask := sr.newlineMasks[chunkIdx]

		// Get quote mask, default to 0 if not present
		var quoteMask uint64
		if chunkIdx < len(sr.quoteMasks) {
			quoteMask = sr.quoteMasks[chunkIdx]
		}

		// Process this chunk's masks
		processChunkMasks(buf, offset, sepMask, nlMask, quoteMask,
			&state, result, &currentRowFirstField, &lineNum)
	}

	// Handle file without trailing newline
	// Need to finalize if:
	// 1. fieldStart < len(buf) - there's content for a final field
	// 2. fieldStart == len(buf) AND last char is not newline - empty final field after separator
	bufLen := uint64(len(buf))
	lastCharIsNewline := bufLen > 0 && (buf[bufLen-1] == '\n' || buf[bufLen-1] == '\r')
	needsFinalize := state.fieldStart < bufLen ||
		(state.fieldStart == bufLen && !lastCharIsNewline)
	if needsFinalize {
		finalizeLastField(buf, &state, result, currentRowFirstField, lineNum)
	}

	// Mark fields needing double quote unescaping based on postProcChunks
	if len(sr.postProcChunks) > 0 {
		postProcessFields(buf, result, sr.postProcChunks)
	}

	return result
}

// processChunkMasks processes one chunk's masks
// Uses bits.TrailingZeros64 to find bit positions and processes
// separator, newline, and quote events in order
func processChunkMasks(
	buf []byte, offset uint64,
	sepMask, nlMask, quoteMask uint64,
	state *parserState, result *parseResult,
	currentRowFirstField, lineNum *int,
) {
	for sepMask != 0 || nlMask != 0 || quoteMask != 0 {
		sepPos := trailingZerosOr64(sepMask)
		nlPos := trailingZerosOr64(nlMask)
		quotePos := trailingZerosOr64(quoteMask)

		minPos := minOfThree(quotePos, sepPos, nlPos)
		if minPos >= 64 {
			break
		}

		switch minPos {
		case quotePos:
			processQuoteEvent(offset+uint64(quotePos), state)
			quoteMask = clearBit(quoteMask, quotePos)

		case sepPos:
			if !state.quoted {
				recordField(buf, offset+uint64(sepPos), state, result, false)
			}
			sepMask = clearBit(sepMask, sepPos)

		default: // nlPos
			if !state.quoted {
				recordField(buf, offset+uint64(nlPos), state, result, true)
				recordRow(result, currentRowFirstField, lineNum)
			}
			nlMask = clearBit(nlMask, nlPos)
		}
	}
}

// trailingZerosOr64 returns bits.TrailingZeros64 or 64 if mask is 0.
func trailingZerosOr64(mask uint64) int {
	if mask == 0 {
		return 64
	}
	return bits.TrailingZeros64(mask)
}

// clearBit clears a bit and all lower bits in a mask.
func clearBit(mask uint64, pos int) uint64 {
	return mask & (^uint64(1) << pos)
}

// processQuoteEvent handles a quote character.
func processQuoteEvent(absPos uint64, state *parserState) {
	if !state.quoted {
		// Opening quote: mark that we're inside a quoted field
		// quoteAdjust = 1 means skip 1 byte (the opening quote) when extracting field content
		state.quoted = true
		state.quoteAdjust = 1
	} else {
		// Closing quote: mark end of quoted field
		// Don't increment quoteAdjust - it should remain 1 to only skip the opening quote
		state.quoted = false
		state.lastClosingQuote = int64(absPos)
	}
}

// recordField calculates field bounds and appends to result.
// If isNewline is true, it checks for and excludes a trailing CR (for CRLF handling).
func recordField(buf []byte, absPos uint64, state *parserState, result *parseResult, isNewline bool) {
	start := state.fieldStart + state.quoteAdjust
	endPos := absPos

	// For newline delimiters, check if the previous byte is CR (CRLF sequence)
	// and exclude it from the field content
	if isNewline && endPos > start && endPos > 0 && buf[endPos-1] == '\r' {
		endPos--
	}

	fieldLen := calculateFieldLength(endPos, start, state)

	result.fields = append(result.fields, fieldInfo{
		start:  start,
		length: fieldLen,
	})

	state.fieldStart = absPos + 1
	state.quoteAdjust = 0
	state.lastSeparatorOrDelimiter = int64(absPos)
	state.lastClosingQuote = -1
}

// recordRow appends row info and updates row tracking state
func recordRow(result *parseResult, currentRowFirstField, lineNum *int) {
	fieldCount := len(result.fields) - *currentRowFirstField
	result.rows = append(result.rows, rowInfo{
		firstField: *currentRowFirstField,
		fieldCount: fieldCount,
		lineNum:    *lineNum,
	})
	*currentRowFirstField = len(result.fields)
	(*lineNum)++
}

// calculateFieldLength computes field length, accounting for quoted fields
func calculateFieldLength(endPos, start uint64, state *parserState) uint64 {
	if state.lastClosingQuote >= 0 && state.quoteAdjust > 0 {
		return uint64(state.lastClosingQuote) - start
	}
	if endPos > start {
		return endPos - start
	}
	return 0
}

// finalizeLastField handles the last field when file doesn't end with newline
func finalizeLastField(buf []byte, state *parserState, result *parseResult, currentRowFirstField, lineNum int) {
	start := state.fieldStart + state.quoteAdjust
	bufLen := uint64(len(buf))
	fieldLen := calculateFieldLength(bufLen, start, state)

	result.fields = append(result.fields, fieldInfo{
		start:  start,
		length: fieldLen,
	})

	fieldCount := len(result.fields) - currentRowFirstField
	result.rows = append(result.rows, rowInfo{
		firstField: currentRowFirstField,
		fieldCount: fieldCount,
		lineNum:    lineNum,
	})
}

// unescapeDoubleQuotes converts double quotes to single quotes
func unescapeDoubleQuotes(s string) string {
	// Fast path: no double quotes
	if !strings.Contains(s, `""`) {
		return s
	}
	return strings.ReplaceAll(s, `""`, `"`)
}

// postProcessFields marks fields needing double quote unescaping
// Fields that fall within chunks listed in postProcChunks are flagged
func postProcessFields(buf []byte, result *parseResult, postProcChunks []int) {
	if len(postProcChunks) == 0 {
		return
	}

	// For each chunk that needs post-processing, find overlapping fields
	for _, chunkIdx := range postProcChunks {
		chunkStart := uint64(chunkIdx * 64)
		chunkEnd := chunkStart + 64

		// Search for fields that start within this chunk range
		for i := range result.fields {
			f := &result.fields[i]
			// Field overlaps with chunk if field starts within chunk
			// or field spans across chunk boundary
			fieldEnd := f.start + f.length
			if (f.start >= chunkStart && f.start < chunkEnd) ||
				(f.start < chunkStart && fieldEnd > chunkStart) {
				// Mark this field as needing unescape processing
				f.needsUnescape = true
			}
		}
	}
}

// extractFieldSafe safely extracts a field string from buffer
func extractFieldSafe(buf []byte, start, length uint64) string {
	if length == 0 {
		return ""
	}
	return string(buf[start : start+length])
}

// extractField extracts a field string, applying unescaping and CRLF normalization if needed.
func extractField(buf []byte, field fieldInfo) string {
	s := extractFieldSafe(buf, field.start, field.length)
	if field.needsUnescape {
		s = unescapeDoubleQuotes(s)
	}
	// Normalize CRLF to LF (matching encoding/csv behavior)
	if strings.Contains(s, "\r\n") {
		s = strings.ReplaceAll(s, "\r\n", "\n")
	}
	return s
}
